{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1738499132.209200  399033 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1738499132.215984  399033 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "import silence_tensorflow.auto\n",
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "tf.debugging.enable_check_numerics()\n",
    "\n",
    "import keras\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1738499136.556610  399033 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3794 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = 1\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 1\n",
    "session = tf.compat.v1.InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = 256\n",
    "W = 256\n",
    "C = 3\n",
    "h = 8\n",
    "\n",
    "P = 16     \n",
    "assert(H == W)\n",
    "assert(H % P == 0)\n",
    "\n",
    "D_model = 1024\n",
    "D_head = 128\n",
    "D_fcn = 2048   \n",
    "num_layers = 4\n",
    "\n",
    "N = (H * W) // (P * P)\n",
    "BS = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLOAT = tf.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1738499136.724807  399033 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3794 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files: 1000\n",
      "Valid images count: 1000\n"
     ]
    }
   ],
   "source": [
    "DS_SHAPE = (512,512,3)\n",
    "def load_and_validate(file_path):\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = tf.image.decode_image(img, channels=C, expand_animations=False)\n",
    "    img = tf.divide(tf.cast(img, dtype=FLOAT), 255.0)\n",
    "    is_valid = tf.reduce_all(tf.equal(tf.shape(img), tf.constant(DS_SHAPE)))\n",
    "\n",
    "    return img, is_valid\n",
    "\n",
    "\n",
    "dataset_path = \"/mnt/Data/ML/datasets/portraits\"\n",
    "num_samples = 1000\n",
    "\n",
    "\n",
    "all_files = [\n",
    "    os.path.join(dataset_path, f)\n",
    "    for f in os.listdir(dataset_path)\n",
    "    if f.endswith((\".jpg\", \".png\"))\n",
    "]\n",
    "random.shuffle(all_files)\n",
    "selected_files = all_files[:num_samples]\n",
    "dataset = tf.data.Dataset.from_tensor_slices(selected_files)\n",
    "dataset = dataset.map(load_and_validate)\n",
    "dataset = dataset.filter(lambda img, is_valid: is_valid)  # Keep valid images\n",
    "dataset = dataset.map(lambda img, is_valid: img)  # remove unused feature\n",
    "dataset = dataset.map(lambda img: tf.image.resize(img, (H,W))) \n",
    "print(f\"Total files: {len(selected_files)}\")\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    valid_count = dataset.reduce(tf.constant(0, dtype=tf.int32), lambda x, _: x + 1).numpy()\n",
    "\n",
    "print(f\"Valid images count: {valid_count}\")\n",
    "assert valid_count, \"Everything's gone\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viz_img(img):\n",
    "    img = tf.cast(img, tf.float32)\n",
    "    plt.imshow(tf.squeeze(img).numpy(), cmap=\"gray\")\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def viz_mask(mask):\n",
    "    plt.imshow(tf.squeeze(mask).numpy(), cmap=\"gray\", vmin=0, vmax=1)\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800 100 100\n"
     ]
    }
   ],
   "source": [
    "def prepare_sample(image):\n",
    "    mask = random_visibility_mask()\n",
    "    return image, mask\n",
    "\n",
    "\n",
    "\n",
    "def random_visibility_mask():\n",
    "    x1 = tf.random.uniform(shape=(), minval=0, maxval=W - 100, dtype=tf.int32)\n",
    "    y1 = tf.random.uniform(shape=(), minval=0, maxval=H - 100, dtype=tf.int32)\n",
    "    x2 = tf.random.uniform(shape=(), minval=x1 + 50, maxval=W + 1, dtype=tf.int32)\n",
    "    y2 = tf.random.uniform(shape=(), minval=y1 + 50, maxval=H + 1, dtype=tf.int32)\n",
    "    # tf.print(x1,x2,y1,y2)\n",
    "\n",
    "    mask = tf.ones((H, W), dtype=tf.bool)\n",
    "    mask = tf.tensor_scatter_nd_update(\n",
    "        mask,\n",
    "        indices=tf.stack(\n",
    "            [\n",
    "                tf.repeat(tf.range(y1, y2), x2 - x1),\n",
    "                tf.tile(tf.range(x1, x2), [y2 - y1]),\n",
    "            ],\n",
    "            axis=-1,\n",
    "        ),\n",
    "        updates=tf.zeros([(y2 - y1) * (x2 - x1)], dtype=tf.bool),\n",
    "    )\n",
    "    return tf.expand_dims(mask, -1)  # expand channel wise\n",
    "\n",
    "ds_masks = dataset.map(prepare_sample)\n",
    "train_count = int(valid_count * 0.8)\n",
    "test_count = int(valid_count * 0.1)\n",
    "val_count = valid_count - train_count - test_count\n",
    "\n",
    "train_ds = ds_masks.take(train_count).batch(BS)\n",
    "test_ds = ds_masks.skip(train_count).take(test_count).batch(BS)\n",
    "val_ds = ds_masks.skip(train_count + test_count).take(val_count).batch(BS)\n",
    "print(train_count, test_count,val_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def mask_area(mask):\n",
    "#     return tf.reduce_sum(tf.cast(mask, tf.int32))\n",
    "\n",
    "\n",
    "def extract_patches(image: tf.Tensor) -> tf.Tensor:\n",
    "    \"R^{BS x H x W x C} -> R^{BS x N x P^2 x C}\"\n",
    "    # print(image.dtype)\n",
    "\n",
    "    patches: tf.Tensor = tf.image.extract_patches(\n",
    "        images=image,  # Add batch dim\n",
    "        sizes=[1, P, P, 1],  # Patch size\n",
    "        strides=[1, P, P, 1],  # Step size\n",
    "        rates=[1, 1, 1, 1],  # No dilation\n",
    "        padding=\"VALID\",\n",
    "    )\n",
    "    BS, H_prime, W_prime, _ = tf.unstack(tf.shape(patches))\n",
    "\n",
    "    # Reshape patches to [BS, H' * W', P*P, C]\n",
    "    patches = tf.reshape(patches, [BS, H_prime * W_prime, P * P, -1])\n",
    "\n",
    "    return patches\n",
    "\n",
    "\n",
    "def patches_to_imgs(patches: tf.Tensor) -> tf.Tensor:\n",
    "    \"R^{BS x N x P^2 x C} -> R^{BS x H x W x C}\"\n",
    "    BS = tf.shape(patches)[0]\n",
    "    grid_size = H // P  # same as W // P\n",
    "\n",
    "    patches = tf.reshape(patches, [BS, grid_size, grid_size, P, P, C])\n",
    "    patches = tf.transpose(patches, perm=[0, 1, 3, 2, 4, 5])\n",
    "\n",
    "    image = tf.reshape(patches, [BS, grid_size * P, grid_size * P, C])\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def process_mask(obvmask: tf.Tensor):\n",
    "    \"R^{BS x H x W} -> tuple[R^{BS x N}, R^{BS x N x N}]\"\n",
    "    # TF does not support min pooling. the mask shown here is OBSERVATION MASK meaning 0 means missing. the inpaint mask is a negation of that\n",
    "\n",
    "    # viz_mask(mask)\n",
    "    BS = tf.shape(obvmask)[0]\n",
    "    mask_pooled = tf.nn.max_pool2d(\n",
    "        tf.cast(\n",
    "            tf.logical_not(obvmask), dtype=tf.int8\n",
    "        ),  # insane shit happaned here with mask_inverted\n",
    "        ksize=[P, P],\n",
    "        strides=[P, P],\n",
    "        padding=\"VALID\",\n",
    "    )\n",
    "    mask_pooled = tf.logical_not(tf.cast(mask_pooled, tf.bool))\n",
    "    # viz_mask(mask_pooled)\n",
    "    mask_pooled = tf.reshape(mask_pooled, [BS, N])\n",
    "    mask_expanded = tf.expand_dims(mask_pooled, axis=1)  # (BS, 1, N)\n",
    "    mask_expanded = tf.tile(mask_expanded, [1, N, 1])  # (BS, N, N)\n",
    "    A = tf.where(\n",
    "        mask_expanded,\n",
    "        tf.constant(0.0, dtype=FLOAT),  # zero penanly\n",
    "        tf.constant(-float(\"inf\"), dtype=FLOAT),  # inf penalty\n",
    "    )\n",
    "    # tf.print(tf.shape(A))\n",
    "\n",
    "    return mask_pooled, A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__CheckNumericsV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} \n\n!!! Detected Infinity or NaN in output 0 of eagerly-executing op \"SelectV2\" (# of outputs: 1) !!!\n  dtype: <dtype: 'float32'>\n  shape: (16, 256, 256)\n  # of -Inf elements: 305920\n\n  Input tensors (3):\n         0: tf.Tensor(\n[[[ True  True  True ...  True  True  True]\n  [ True  True  True ...  True  True  True]\n  [ True  True  True ...  True  True  True]\n  ...\n  [ True  True  True ...  True  True  True]\n  [ True  True  True ...  True  True  True]\n  [ True  True  True ...  True  True  True]]\n\n [[ True  True  True ...  True  True  True]\n  [ True  True  True ...  True  True  True]\n  [ True  True  True ...  True  True  True]\n  ...\n  [ True  True  True ...  True  True  True]\n  [ True  True  True ...  True  True  True]\n  [ True  True  True ...  True  True  True]]\n\n [[ True  True  True ...  True  True  True]\n  [ True  True  True ...  True  True  True]\n  [ True  True  True ...  True  True  True]\n  ...\n  [ True  True  True ...  True  True  True]\n  [ True  True  True ...  True  True  True]\n  [ True  True  True ...  True  True  True]]\n\n ...\n\n [[ True  True  True ...  True  True  True]\n  [ True  True  True ...  True  True  True]\n  [ True  True  True ...  True  True  True]\n  ...\n  [ True  True  True ...  True  True  True]\n  [ True  True  True ...  True  True  True]\n  [ True  True  True ...  True  True  True]]\n\n [[ True  True  True ... False False  True]\n  [ True  True  True ... False False  True]\n  [ True  True  True ... False False  True]\n  ...\n  [ True  True  True ... False False  True]\n  [ True  True  True ... False False  True]\n  [ True  True  True ... False False  True]]\n\n [[ True  True  True ...  True  True  True]\n  [ True  True  True ...  True  True  True]\n  [ True  True  True ...  True  True  True]\n  ...\n  [ True  True  True ...  True  True  True]\n  [ True  True  True ...  True  True  True]\n  [ True  True  True ...  True  True  True]]], shape=(16, 256, 256), dtype=bool)\n         1: tf.Tensor(0.0, shape=(), dtype=float32)\n         2: tf.Tensor(-inf, shape=(), dtype=float32)\n\n : Tensor had -Inf values [Op:CheckNumericsV2] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 140\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m patches_to_imgs(reconstructed_patches)\n\u001b[1;32m    139\u001b[0m model \u001b[38;5;241m=\u001b[39m ImageInpaintingTransformer()\n\u001b[0;32m--> 140\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mC\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.8/envs/tf312/lib/python3.12/site-packages/keras/src/layers/layer.py:226\u001b[0m, in \u001b[0;36mLayer.__new__.<locals>.build_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_open_name_scope():\n\u001b[1;32m    225\u001b[0m     obj\u001b[38;5;241m.\u001b[39m_path \u001b[38;5;241m=\u001b[39m current_path()\n\u001b[0;32m--> 226\u001b[0m     \u001b[43moriginal_build_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;66;03m# Record build config.\u001b[39;00m\n\u001b[1;32m    228\u001b[0m signature \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(original_build_method)\n",
      "Cell \u001b[0;32mIn[8], line 119\u001b[0m, in \u001b[0;36mImageInpaintingTransformer.build\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    117\u001b[0m BS \u001b[38;5;241m=\u001b[39m input_shape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    118\u001b[0m \u001b[38;5;66;03m# dummy_images = tf.zeros((BS, H, W, C), dtype=FLOAT)  # THIS WASTED 40 MINUTES\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mval_ds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[8], line 126\u001b[0m, in \u001b[0;36mImageInpaintingTransformer.call\u001b[0;34m(self, image, obvmask)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m# viz_img(image[0])\u001b[39;00m\n\u001b[1;32m    125\u001b[0m patches \u001b[38;5;241m=\u001b[39m extract_patches(image)\n\u001b[0;32m--> 126\u001b[0m mask_pooled, A \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobvmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;66;03m# tf.print(tf.shape(A))\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;66;03m# viz_img(A)\u001b[39;00m\n\u001b[1;32m    130\u001b[0m BS \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mshape(patches)[\u001b[38;5;241m0\u001b[39m]\n",
      "Cell \u001b[0;32mIn[6], line 90\u001b[0m, in \u001b[0;36mprocess_mask\u001b[0;34m(obvmask)\u001b[0m\n\u001b[1;32m     88\u001b[0m mask_expanded \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mexpand_dims(mask_pooled, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# (BS, 1, N)\u001b[39;00m\n\u001b[1;32m     89\u001b[0m mask_expanded \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mtile(mask_expanded, [\u001b[38;5;241m1\u001b[39m, N, \u001b[38;5;241m1\u001b[39m])  \u001b[38;5;66;03m# (BS, N, N)\u001b[39;00m\n\u001b[0;32m---> 90\u001b[0m A \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask_expanded\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# zero penanly\u001b[39;49;00m\n\u001b[1;32m     93\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# inf penalty\u001b[39;49;00m\n\u001b[1;32m     94\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;66;03m# tf.print(tf.shape(A))\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mask_pooled, A\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.8/envs/tf312/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.8/envs/tf312/lib/python3.12/site-packages/tensorflow/python/framework/ops.py:6002\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6000\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[1;32m   6001\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m-> 6002\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__CheckNumericsV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} \n\n!!! Detected Infinity or NaN in output 0 of eagerly-executing op \"SelectV2\" (# of outputs: 1) !!!\n  dtype: <dtype: 'float32'>\n  shape: (16, 256, 256)\n  # of -Inf elements: 305920\n\n  Input tensors (3):\n         0: tf.Tensor(\n[[[ True  True  True ...  True  True  True]\n  [ True  True  True ...  True  True  True]\n  [ True  True  True ...  True  True  True]\n  ...\n  [ True  True  True ...  True  True  True]\n  [ True  True  True ...  True  True  True]\n  [ True  True  True ...  True  True  True]]\n\n [[ True  True  True ...  True  True  True]\n  [ True  True  True ...  True  True  True]\n  [ True  True  True ...  True  True  True]\n  ...\n  [ True  True  True ...  True  True  True]\n  [ True  True  True ...  True  True  True]\n  [ True  True  True ...  True  True  True]]\n\n [[ True  True  True ...  True  True  True]\n  [ True  True  True ...  True  True  True]\n  [ True  True  True ...  True  True  True]\n  ...\n  [ True  True  True ...  True  True  True]\n  [ True  True  True ...  True  True  True]\n  [ True  True  True ...  True  True  True]]\n\n ...\n\n [[ True  True  True ...  True  True  True]\n  [ True  True  True ...  True  True  True]\n  [ True  True  True ...  True  True  True]\n  ...\n  [ True  True  True ...  True  True  True]\n  [ True  True  True ...  True  True  True]\n  [ True  True  True ...  True  True  True]]\n\n [[ True  True  True ... False False  True]\n  [ True  True  True ... False False  True]\n  [ True  True  True ... False False  True]\n  ...\n  [ True  True  True ... False False  True]\n  [ True  True  True ... False False  True]\n  [ True  True  True ... False False  True]]\n\n [[ True  True  True ...  True  True  True]\n  [ True  True  True ...  True  True  True]\n  [ True  True  True ...  True  True  True]\n  ...\n  [ True  True  True ...  True  True  True]\n  [ True  True  True ...  True  True  True]\n  [ True  True  True ...  True  True  True]]], shape=(16, 256, 256), dtype=bool)\n         1: tf.Tensor(0.0, shape=(), dtype=float32)\n         2: tf.Tensor(-inf, shape=(), dtype=float32)\n\n : Tensor had -Inf values [Op:CheckNumericsV2] name: "
     ]
    }
   ],
   "source": [
    "class PatchEmbedding(keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__(dtype=FLOAT)  \n",
    "        self.proj = keras.layers.Dense(D_model, dtype=FLOAT)  # (P² * C) -> D_model\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        positions = tf.range(N, dtype=FLOAT)\n",
    "        positions = tf.expand_dims(positions, 1)  # (N, 1)\n",
    "        i = tf.range(D_model//2, dtype=FLOAT)\n",
    "        div_term = tf.exp(\n",
    "        (2.0 * i) * (-tf.math.log(10000.0) / D_model)\n",
    "        )\n",
    "        angles = positions * div_term  # (N, D_model//2)\n",
    "        sin_terms = tf.sin(angles)\n",
    "        cos_terms = tf.cos(angles)\n",
    "            \n",
    "        self.positional_embedding = tf.reshape(tf.stack([sin_terms, cos_terms], axis=-1), [N, D_model])\n",
    "        # tf.print(self.positional_embedding)\n",
    "\n",
    "    def call(self, patches_flat: tf.Tensor):\n",
    "        # R^{BS x N x (P^2 . C)} -> R^{BS x N x D_model}\n",
    "        X = self.proj(patches_flat) \n",
    "        X += self.positional_embedding \n",
    "        return X\n",
    "\n",
    "\n",
    "class MultiHeadAttention(keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__(dtype=FLOAT)\n",
    "        # Project to h * D_head dimensions\n",
    "        self.W_Q = keras.layers.Dense(h * D_head, dtype=FLOAT)\n",
    "        self.W_K = keras.layers.Dense(h * D_head, dtype=FLOAT)\n",
    "        self.W_V = keras.layers.Dense(h * D_head, dtype=FLOAT)\n",
    "        # Project back to D_model\n",
    "        self.W_O = keras.layers.Dense(D_model, dtype=FLOAT)\n",
    "\n",
    "    def call(self, X, A):\n",
    "        # X: R^{BS x N x D_model}\n",
    "        # A: R^{BS x N x N}\n",
    "        # returns: R^{BS x N x D_model}\n",
    "\n",
    "        # In the standard implementation, each head has its own separate projection matrices. However, a common optimization is to project the input into h * D_head dimensions (which is D_model) with a single large projection, then split into h heads. So, if D_model = h * D_head, then using a Dense(D_model) for Q, K, V and then splitting into h heads each of D_head is equivalent to having h separate projections. This is a standard approach because it's more efficient to compute all heads in parallel with a single matrix multiplication rather than h separate ones.\n",
    "        # So the optimal way is to use combined projections.\n",
    "        Q = self.W_Q(X)  # (BS, N, h * D_head)\n",
    "        K = self.W_K(X)  # (BS, N, h * D_head)\n",
    "        V = self.W_V(X)  # (BS, N, h * D_head)\n",
    "        \n",
    "\n",
    "        Q = tf.reshape(Q, (-1, N, h, D_head))  # (BS, N, h, D_head)\n",
    "        K = tf.reshape(K, (-1, N, h, D_head))\n",
    "        V = tf.reshape(V, (-1, N, h, D_head))\n",
    "\n",
    "        # Transpose for attention computation\n",
    "        Q = tf.transpose(Q, [0, 2, 1, 3])  # (BS, h, N, D_head)\n",
    "        K = tf.transpose(K, [0, 2, 1, 3])\n",
    "        V = tf.transpose(V, [0, 2, 1, 3])\n",
    "        # scaled dot-product attention\n",
    "        attn_scores = tf.matmul(Q, K, transpose_b=True)  # (BS, h, N, N)\n",
    "        attn_scores /= tf.math.sqrt(\n",
    "            tf.cast(D_head, attn_scores.dtype)\n",
    "        )  # scale by sqrt(D_head)\n",
    "\n",
    "        A = tf.expand_dims(A, 1)  # (BS, 1, N, N)\n",
    "        attn_scores += A  # Broadcast to all heads\n",
    "\n",
    "        attn_weights = tf.nn.softmax(attn_scores, axis=-1)  # (BS, h, N, N)\n",
    "\n",
    "        output = tf.matmul(attn_weights, V)  # (BS, h, N, D_head)\n",
    "        output = tf.transpose(output, [0, 2, 1, 3])  # (BS, N, h, D_head)\n",
    "        output = tf.reshape(output, (-1, N, h * D_head))  # (BS, N, h * D_head)\n",
    "        output = self.W_O(output)  # (BS, N, D_model)\n",
    "        return output\n",
    "\n",
    "\n",
    "class TransformerBlock(keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__(dtype=FLOAT)\n",
    "        self.attn = MultiHeadAttention()\n",
    "        self.norm1 = keras.layers.LayerNormalization(dtype=FLOAT)\n",
    "        self.norm2 = keras.layers.LayerNormalization(dtype=FLOAT)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [\n",
    "                keras.layers.Dense(D_fcn, activation=\"gelu\", dtype=FLOAT),\n",
    "                keras.layers.Dense(D_model, dtype=FLOAT),\n",
    "                # keras.layers.Dropout(0.1, dtype=FLOAT),\n",
    "            ],\n",
    "        )\n",
    "\n",
    "    def call(self, X, A):\n",
    "        \"R^{N x D_model} -> R^{N x D_model}\"\n",
    "        X = self.norm1(X + self.attn(X, A))\n",
    "        X = self.norm2(X + self.ffn(X))\n",
    "        return X\n",
    "\n",
    "\n",
    "class Decoder(keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__(dtype=FLOAT)\n",
    "        self.proj = keras.layers.Dense(P * P * C, dtype=FLOAT)\n",
    "\n",
    "    def call(self, X):\n",
    "        \"R^{BS x N x D_model} -> R^{BS x N x P x P x C}\"\n",
    "        BS = tf.shape(X)[0]\n",
    "        X = self.proj(X)\n",
    "        X = tf.reshape(X, (BS, N, P, P, C))\n",
    "        return X\n",
    "\n",
    "\n",
    "class ImageInpaintingTransformer(keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__(dtype=FLOAT)\n",
    "        self.embed = PatchEmbedding()\n",
    "        self.transformer_blocks = [TransformerBlock() for _ in range(num_layers)]\n",
    "        self.decoder = Decoder()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        BS = input_shape[0]\n",
    "        # dummy_images = tf.zeros((BS, H, W, C), dtype=FLOAT)  # THIS WASTED 40 MINUTES\n",
    "        self.call(*next(iter(val_ds.take(1))))\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, image, obvmask):\n",
    "        image = tf.multiply(image, tf.cast(obvmask,FLOAT))\n",
    "        # viz_img(image[0])\n",
    "        patches = extract_patches(image)\n",
    "        mask_pooled, A = process_mask(obvmask)\n",
    "        # tf.print(tf.shape(A))\n",
    "        # viz_img(A)\n",
    "\n",
    "        BS = tf.shape(patches)[0]\n",
    "        patches_flat = tf.reshape(patches, [BS, N, P**2 * C])\n",
    "        # tf.print(tf.shape(patches_flat))\n",
    "        X = self.embed(patches_flat)\n",
    "        for block in self.transformer_blocks:\n",
    "            X = block(X, A)\n",
    "        reconstructed_patches = self.decoder(X)  # R^{BS x N x P x P x C}\n",
    "        return patches_to_imgs(reconstructed_patches)\n",
    "\n",
    "model = ImageInpaintingTransformer()\n",
    "model.build((BS, H, W, C))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Tests patching and depatching\n",
    "\n",
    "# img = next(iter(dataset.take(1)))\n",
    "\n",
    "# viz_img(img)\n",
    "# patched = extract_patches(tf.expand_dims(img ,0))\n",
    "# tf.print(tf.shape(patched))\n",
    "\n",
    "# recreated_img = patches_to_imgs(patched)\n",
    "# viz_img(recreated_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_weights(\"best_run.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_epochs = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def costfunc(y_true: tf.Tensor, y_pred: tf.Tensor, obsvmask: tf.Tensor):\n",
    "    errors = tf.abs(tf.subtract(y_true, y_pred))\n",
    "    inpaintmask = tf.cast(tf.logical_not(obsvmask), FLOAT)\n",
    "    masked_errors = tf.multiply(errors, inpaintmask)\n",
    "    sum_masked_errors = tf.reduce_sum(masked_errors)\n",
    "    area = tf.reduce_sum(inpaintmask)\n",
    "    masked_loss = sum_masked_errors / (area + keras.backend.epsilon())\n",
    "\n",
    "    global_loss = tf.reduce_mean(errors)\n",
    "\n",
    "    return masked_loss + global_loss\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=1e-5 , clipvalue=1.0)\n",
    "\n",
    "@tf.function\n",
    "def train_step(image: tf.Tensor, mask: tf.Tensor):\n",
    "    with tf.GradientTape() as tape:\n",
    "        reconstructed_img = model(image, mask)  # N x P x P x C\n",
    "        loss = costfunc(image, reconstructed_img, mask)\n",
    "        tf.debugging.check_numerics(loss, \"Loss contains NaN or Inf.\") \n",
    "        # if (tf.math.is_nan(loss)):\n",
    "            # raise Exception(\"Divergence\")\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def val_step(image: tf.Tensor, mask: tf.Tensor):\n",
    "    reconstructed_img = model(image, mask, training = False)\n",
    "    loss = costfunc(image, reconstructed_img, mask)\n",
    "    return loss\n",
    "\n",
    "\n",
    "epochs = 50\n",
    "print(\"Starting training\")\n",
    "\n",
    "best_val_loss = float(\"inf\")\n",
    "best_epoch = -1\n",
    "for _ in range(epochs):\n",
    "    epoch_loss = 0.0\n",
    "    steps = 0\n",
    "    pbar = tqdm(train_ds, desc=f\"Epoch {session_epochs+1}\", unit=\"batch\", total=train_count // BS)\n",
    "    for image_batch, mask_batch in pbar:\n",
    "        loss = train_step(image_batch, mask_batch)\n",
    "        epoch_loss += loss\n",
    "        steps += 1\n",
    "        # Dynamically update the tqdm bar without spamming stdout\n",
    "        pbar.set_postfix(loss=f\"{loss:.4f}\")\n",
    "    train_loss = epoch_loss / steps\n",
    "\n",
    "    val_loss_total = 0.0\n",
    "    val_steps = 0\n",
    "    pbar_val = tqdm(val_ds, desc=f\"Epoch {session_epochs+1} Validation\", unit=\"batch\", total=val_count // BS)\n",
    "    for val_image_batch, val_mask_batch in pbar_val:\n",
    "        loss = val_step(val_image_batch, val_mask_batch)\n",
    "        val_loss_total += loss\n",
    "        val_steps += 1\n",
    "        pbar_val.set_postfix(loss=f\"{loss:.4f}\")\n",
    "    avg_val_loss = val_loss_total / val_steps\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        best_epoch = session_epochs + 1\n",
    "        model.save(\"best_run.keras\")\n",
    "    print(f\"Epoch {session_epochs+1} Summary: Train Loss = {train_loss:.4f} | Validation Loss = {avg_val_loss:.4f}\")\n",
    "    session_epochs+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"b4.keras\")\n",
    "# model.load_weights(\"best_run.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_obsv_mask(image: tf.Tensor, obvmask: tf.Tensor) -> tf.Tensor:\n",
    "    return tf.multiply(image, tf.cast(obvmask, FLOAT))\n",
    "\n",
    "\n",
    "def viz_grid(batch: tf.Tensor):\n",
    "    batch_size: int = batch.shape[0]  # type: ignore\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=batch_size, figsize=(15, 15), dpi=300)\n",
    "    if batch_size == 1:\n",
    "        axes = [axes]\n",
    "    for i in range(batch_size):\n",
    "        # Original image\n",
    "        axes[i].imshow(tf.cast(batch[i], dtype=tf.float32).numpy())  # type: ignore\n",
    "        axes[i].axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def reconstruct(original: tf.Tensor, reconstruct: tf.Tensor, obvmask: tf.Tensor):\n",
    "    return tf.add(\n",
    "        tf.multiply(tf.cast(obvmask, FLOAT), original),\n",
    "        tf.multiply(tf.cast(tf.logical_not(obvmask), FLOAT), reconstruct),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qualitative Eval\n",
    "# visualize_unbatched_dataset(test_ds, 5)\n",
    "\n",
    "\n",
    "# img = tf.image.decode_image(\n",
    "#     tf.io.read_file(\"/home/navid/Dev/PaperTex/impl/naruto\")\n",
    "#     , dtype=tf.float32)\n",
    "# img = tf.image.resize_with_crop_or_pad(img, H, W)\n",
    "# img = tf.expand_dims(img, 0)\n",
    "# tf.print(tf.shape(img))\n",
    "# obvmask = tf.expand_dims(random_visibility_mask(),0)\n",
    "# tf.print(tf.shape(obvmask))\n",
    "\n",
    "\n",
    "img, obvmask = next(iter(test_ds.take(1)))\n",
    "viz_grid(img)\n",
    "viz_grid(apply_obsv_mask(img, obvmask))\n",
    "model_out = model(img, obvmask)\n",
    "# reconstructed = reconstruct(img, model(img, obvmask), obvmask)\n",
    "viz_grid(model_out)\n",
    "\n",
    "# viz_img(model_out[0])\n",
    "# viz_img(img[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
