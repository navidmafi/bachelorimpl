{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# terminology:\n",
    "# obs_mask:  1 = observed,   0 = hole\n",
    "# hole_mask: 1 = hole,       0 = not hole (observed)\n",
    "\n",
    "# Absolutely lovely state of typesafety in this godforsaken ecosystem. We will use underscores a lot ...\n",
    "# I will try to minimize usage of tf.cast\n",
    "\n",
    "# we place emphasis on determinism\n",
    "# only change one parameter (optimizer/dataset/hyperparams/overall architecture) in experiments. Let's put all that determinism effort into good use and isolate changes for meaningful observations.\n",
    "\n",
    "\n",
    "GLOBAL_RANDOM_SEED = 42\n",
    "\n",
    "from datetime import datetime\n",
    "import os, uuid\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "import pathlib\n",
    "import subprocess, random\n",
    "\n",
    "# import sys\n",
    "# IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "os.environ[\"PYTHONHASHSEED\"] = f\"{GLOBAL_RANDOM_SEED}\"\n",
    "os.environ[\"TF_DETERMINISTIC_OPS\"] = \"1\"\n",
    "os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = \"1\"\n",
    "import tensorflow as tf\n",
    "\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.9\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.compat.v1.InteractiveSession(config=config)\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "import keras\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "# tf.config.threading.set_intra_op_parallelism_threads(1)\n",
    "# tf.config.threading.set_inter_op_parallelism_threads(1)\n",
    "\n",
    "WAN = False\n",
    "if WAN:\n",
    "    wandb.login(key=os.environ['WANDB_TOKEN'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "EPOCHS_TO_TRAIN = 10\n",
    "num_samples = 10000\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "H = 128\n",
    "W = 128\n",
    "C = 3\n",
    "\n",
    "P = 8\n",
    "assert H == W\n",
    "assert H % P == 0\n",
    "\n",
    "heads = 8\n",
    "\n",
    "D_model = 768\n",
    "D_head = 128\n",
    "D_fcn = 768\n",
    "num_layers = 8\n",
    "N = (H * W) // (P * P)\n",
    "\n",
    "MASK_MAX_SIZE = 20\n",
    "MASK_MIN_SIZE = 20\n",
    "assert MASK_MAX_SIZE < H / 2\n",
    "\n",
    "optimizer = keras.optimizers.AdamW(learning_rate=1e-4, weight_decay=1e-2)\n",
    "# optimizer = keras.optimizers.Adam(learning_rate=1e-4)\n",
    "\n",
    "# keras.mixed_precision.set_global_policy(\"mixed_float16\")\n",
    "# FLOAT = tf.float16\n",
    "FLOAT = tf.float32"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def viz_img(image):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    plt.imshow(tf.squeeze(image).numpy(), cmap=\"gray\")\n",
    "    plt.colorbar()\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    plt.text(\n",
    "        0.99,\n",
    "        0.01,\n",
    "        timestamp,\n",
    "        ha=\"right\",\n",
    "        va=\"bottom\",\n",
    "        transform=plt.gca().transAxes,\n",
    "        fontsize=12,\n",
    "        color=\"white\",\n",
    "        alpha=0.9,\n",
    "        bbox=dict(boxstyle=\"square,pad=0.1\", facecolor=\"black\", alpha=0.3),\n",
    "    )\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def viz_mask(mask):\n",
    "    plt.imshow(tf.squeeze(mask).numpy(), cmap=\"gray\", vmin=0, vmax=1)\n",
    "    plt.colorbar()\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    plt.text(\n",
    "        0.99,\n",
    "        0.01,\n",
    "        timestamp,\n",
    "        ha=\"right\",\n",
    "        va=\"bottom\",\n",
    "        transform=plt.gca().transAxes,\n",
    "        fontsize=12,\n",
    "        color=\"white\",\n",
    "        alpha=0.9,\n",
    "        bbox=dict(boxstyle=\"square,pad=0.1\", facecolor=\"black\", alpha=0.3),\n",
    "    )\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def viz_grid(batch: tf.Tensor, max_samples: int = 4):\n",
    "    batch_size: int = batch.shape[0]  # type: ignore\n",
    "    num = min(batch_size, max_samples)\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=num, figsize=(15, 15), dpi=300)\n",
    "    if num == 1:\n",
    "        axes = [axes]\n",
    "    for i in range(num):\n",
    "        # Original image\n",
    "        axes[i].imshow(\n",
    "            tf.clip_by_value(\n",
    "                tf.cast(batch[i], dtype=tf.float32), 0, 1  # type: ignore\n",
    "            ).numpy(),  # type: ignore\n",
    "            cmap='gray'\n",
    "        )\n",
    "        axes[i].axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def random_obs_mask(canvas_height, canvas_width, min_size, max_size, idx):\n",
    "    seed = tf.stack([tf.cast(GLOBAL_RANDOM_SEED, tf.int32), tf.cast(idx, tf.int32)])\n",
    "    sizes = tf.random.stateless_uniform(\n",
    "        [2], minval=min_size, maxval=max_size + 1, dtype=tf.int32, seed=seed\n",
    "    )\n",
    "    w = sizes[0]\n",
    "    h = sizes[1]\n",
    "    x = tf.random.stateless_uniform(\n",
    "        [], minval=0, maxval=canvas_width - w + 1, dtype=tf.int32, seed=seed + 1\n",
    "    )\n",
    "    y = tf.random.stateless_uniform(\n",
    "        [], minval=0, maxval=canvas_height - h + 1, dtype=tf.int32, seed=seed + 2\n",
    "    )\n",
    "\n",
    "    mask = tf.ones([canvas_height, canvas_width], dtype=FLOAT)\n",
    "\n",
    "    # TensorFlow-friendly indexing\n",
    "    ys = tf.range(y, y + h)\n",
    "    xs = tf.range(x, x + w)\n",
    "    yy, xx = tf.meshgrid(ys, xs, indexing='ij')\n",
    "    indices = tf.stack([tf.reshape(yy, [-1]), tf.reshape(xx, [-1])], axis=1)\n",
    "\n",
    "    updates = tf.zeros([h * w], dtype=FLOAT)\n",
    "    mask = tf.tensor_scatter_nd_update(mask, indices, updates)\n",
    "    mask = tf.expand_dims(mask, -1)\n",
    "    mask.set_shape([canvas_height, canvas_width, 1])\n",
    "    return mask\n",
    "\n",
    "\n",
    "# we previously did return a tuple with the second param being an \"is_valid\" boolean,\n",
    "# but we mostly should work with clean curated datasets (and preprocessing is not our job)\n",
    "# doing this ensures we can benefit from cheap .cardinality() calls instead of enumerating\n",
    "# the whole dataset to find actual cardinality to then use in downstream tasks (split/etc)\n",
    "# tl;dr: it's not every day you get to work with datasets that don't maintain a consistent resolution\n",
    "def load_strict(file_path, expected_shape):\n",
    "    img_bytes = tf.io.read_file(file_path)\n",
    "    img = tf.image.decode_image(img_bytes, channels=expected_shape[2], expand_animations=False)\n",
    "    img = tf.cast(img, FLOAT) / 255.0\n",
    "\n",
    "    # Raise in TF if shape mismatches.\n",
    "    actual_shape = tf.shape(img)\n",
    "    tf.debugging.assert_equal(\n",
    "        actual_shape,\n",
    "        tf.constant(expected_shape, dtype=tf.int32),\n",
    "        message=f\"Shape mismatch for {file_path}\"\n",
    "    )\n",
    "\n",
    "    img.set_shape(expected_shape)\n",
    "    return img"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ds_shape_advertised = (512, 512, 3)\n",
    "\n",
    "DOWNLOAD_THREADS = 4\n",
    "filelist = pathlib.Path(\"filelist\")\n",
    "if not filelist.exists():\n",
    "    out = subprocess.check_output(\n",
    "        [\"rsync\", \"--no-motd\", \"--list-only\", \"rsync://176.9.41.242:873/biggan/portraits/\"],  # ~17 sec\n",
    "        text=True\n",
    "    )\n",
    "    with open(\"filelist\", \"w\") as f:\n",
    "        f.write(out)\n",
    "\n",
    "f = open(\"filelist\", \"r\")\n",
    "\n",
    "files = sorted(line.split()[-1] for line in f.read().splitlines() if line.strip())\n",
    "ds_select_rng = random.Random(GLOBAL_RANDOM_SEED)\n",
    "ds_select_rng.shuffle(files)\n",
    "selected_files = files[:num_samples]\n",
    "chunks = [selected_files[i::DOWNLOAD_THREADS] for i in range(DOWNLOAD_THREADS)]\n",
    "pathlib.Path(\"portraits\").mkdir(exist_ok=True)\n",
    "procs = []\n",
    "for chunk in chunks:\n",
    "    proc = subprocess.run([\n",
    "        \"rsync\", \"-avR\", \"--ignore-existing\", \"--files-from=-\",\n",
    "        \"rsync://176.9.41.242:873/biggan/portraits/\", \"./portraits/\"\n",
    "    ], text=True, input=\"\\n\".join(chunk), check=True, stderr=subprocess.PIPE)\n",
    "for p in procs: p.wait()\n",
    "base = tf.constant(\"portraits/\")\n",
    "dataset = tf.data.Dataset.from_tensor_slices(selected_files)\n",
    "dataset = dataset.map(lambda x: tf.strings.join([base, x]))\n",
    "dataset = dataset.map(\n",
    "    lambda img: load_strict(img, ds_shape_advertised),\n",
    "    num_parallel_calls=AUTOTUNE,\n",
    ")\n",
    "\n",
    "dataset = dataset.map(\n",
    "    lambda img: tf.image.resize(img, (H, W)),\n",
    "    num_parallel_calls=AUTOTUNE,\n",
    ")\n",
    "\n",
    "if C == 1 and ds_shape_advertised[2] == 3:\n",
    "    dataset = dataset.map(\n",
    "        lambda img: tf.image.rgb_to_grayscale(img),\n",
    "        num_parallel_calls=AUTOTUNE,\n",
    "    )\n",
    "\n",
    "dataset = dataset.enumerate()\n",
    "dataset = dataset.map(\n",
    "    lambda idx, img: (img, random_obs_mask(H, W, MASK_MIN_SIZE, MASK_MAX_SIZE, idx)),\n",
    "    num_parallel_calls=AUTOTUNE  # must be single-threaded for deterministic order\n",
    ")\n",
    "ds_count = dataset.cardinality().numpy()\n",
    "print(f\"Dataset has {ds_count} samples\")\n",
    "sample_img, sample_mask = next(iter(dataset))\n",
    "print(\"img\", sample_img.shape, \"mask\", sample_mask.shape)\n",
    "\n",
    "train_count = int(ds_count * 0.8)\n",
    "test_count = int(ds_count * 0.1)\n",
    "val_count = ds_count - train_count - test_count\n",
    "\n",
    "train_ds = dataset.take(train_count).batch(BATCH_SIZE)\n",
    "test_ds = dataset.skip(train_count).take(test_count).batch(BATCH_SIZE)\n",
    "val_ds = dataset.skip(train_count + test_count).take(val_count).batch(BATCH_SIZE)\n",
    "\n",
    "train_batches = -(train_count // -BATCH_SIZE)\n",
    "test_batches = -(test_count // -BATCH_SIZE)\n",
    "val_batches = -(val_count // -BATCH_SIZE)\n",
    "\n",
    "print(\"Trn,Tst,Val:\", train_count, test_count, val_count)\n",
    "print(\"Trn,Tst,Val batches:\", train_batches, test_batches, val_batches)\n",
    "viz_grid(next(iter(train_ds.take(1).map(lambda img, mask: img))), 8)  # type: ignore\n",
    "viz_grid(next(iter(train_ds.take(1).map(lambda img, mask: mask))), 8)  # type: ignore"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def extract_patches(image: tf.Tensor) -> tf.Tensor:\n",
    "    \"\"\"R^{BS x H x W x C} -> R^{BS x N x P^2 x C}\"\"\"\n",
    "\n",
    "    patches: tf.Tensor = tf.image.extract_patches(\n",
    "        images=image,\n",
    "        sizes=[1, P, P, 1],\n",
    "        strides=[1, P, P, 1],\n",
    "        rates=[1, 1, 1, 1],\n",
    "        padding=\"VALID\",\n",
    "    )\n",
    "    bs, h_prime, w_prime, _ = tf.unstack(tf.shape(patches))\n",
    "\n",
    "    # Reshape patches to [BS, H' * W', P*P, C]\n",
    "    patches = tf.reshape(patches, [bs, h_prime * w_prime, P * P, -1])\n",
    "\n",
    "    return patches\n",
    "\n",
    "\n",
    "def patches_to_imgs(patches: tf.Tensor) -> tf.Tensor:\n",
    "    \"\"\"R^{BS x N x P.P.C} -> R^{BS x H x W x C}\"\"\"\n",
    "    bs = tf.shape(patches)[0]\n",
    "    grid_size = H // P  # same as W // P\n",
    "    patches = tf.reshape(patches, [bs, grid_size, grid_size, P, P, C])\n",
    "    patches = tf.transpose(patches, perm=[0, 1, 3, 2, 4, 5])\n",
    "    image = tf.reshape(patches, [bs, grid_size * P, grid_size * P, C])\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "sample_img, sample_mask = next(iter(dataset.take(1)))\n",
    "sample_img = tf.expand_dims(sample_img, 0)\n",
    "tf.assert_equal(patches_to_imgs(extract_patches(sample_img)), sample_img)\n",
    "\n",
    "\n",
    "def create_attention_mask(obs_mask_bool: tf.Tensor):\n",
    "    \"\"\"R^{BS x H x W} -> R^{BS x N x N}\"\"\"\n",
    "    # TF does not support native min pooling.\n",
    "    # The mask shown is OBSERVATION MASK meaning 0 means missing.\n",
    "\n",
    "    bs = tf.shape(obs_mask_bool)[0]\n",
    "    mask_pooled = tf.nn.max_pool2d(\n",
    "        tf.cast(tf.logical_not(obs_mask_bool), dtype=tf.int8),\n",
    "        ksize=[P, P],\n",
    "        strides=[P, P],\n",
    "        padding=\"VALID\",\n",
    "    )\n",
    "    mask_pooled = tf.logical_not(tf.cast(mask_pooled, tf.bool))\n",
    "    # viz_mask(mask_pooled)\n",
    "    mask_pooled = tf.reshape(mask_pooled, [bs, N])\n",
    "    mask_expanded = tf.expand_dims(mask_pooled, axis=1)  # (BS, 1, N)\n",
    "    mask_expanded = tf.tile(mask_expanded, [1, N, 1])  # (BS, N, N)\n",
    "    attn_mask = tf.where(\n",
    "        mask_expanded,\n",
    "        tf.constant(0.0, dtype=FLOAT),  # zero penalty\n",
    "        tf.constant(-float(\"inf\"), dtype=FLOAT),  # inf penalty\n",
    "    )\n",
    "    return attn_mask\n",
    "\n",
    "\n",
    "def apply_obs_mask(image: tf.Tensor, obs_mask_float: tf.Tensor) -> tf.Tensor:\n",
    "    return tf.multiply(image, obs_mask_float)\n",
    "\n",
    "\n",
    "def reconstruct(\n",
    "        original: tf.Tensor, inpainted: tf.Tensor, obs_mask_float: tf.Tensor\n",
    ") -> tf.Tensor:\n",
    "    obs_mask_bool = tf.cast(obs_mask_float, dtype=tf.bool)\n",
    "    return tf.add(\n",
    "        tf.multiply(tf.cast(obs_mask_bool, FLOAT), original),\n",
    "        tf.multiply(tf.cast(tf.logical_not(obs_mask_bool), FLOAT), inpainted),\n",
    "    )\n",
    "\n",
    "# sample = next(iter(train_ds.unbatch().take(1)))\n",
    "# print(sample[0].dtype)\n",
    "# viz_img(sample[0])\n",
    "# viz_mask(sample[1])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "initializer = keras.initializers.GlorotUniform(seed=GLOBAL_RANDOM_SEED)\n",
    "\n",
    "commonDense = {\"dtype\": FLOAT, \"kernel_initializer\": initializer}\n",
    "\n",
    "\n",
    "class PatchEmbedding(keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__(dtype=FLOAT)\n",
    "        self.positional_embedding = None\n",
    "        self.proj = keras.layers.Dense(D_model, **commonDense)  # (P² * C) -> D_model\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.positional_embedding = self.add_weight(\n",
    "            shape=(N, D_model), initializer=initializer, name=\"pos_embed\"\n",
    "        )\n",
    "\n",
    "    def call(self, patches_flat: tf.Tensor):\n",
    "        # R^{BS x N x (P^2 . C)} -> R^{BS x N x D_model}\n",
    "        X = self.proj(patches_flat)\n",
    "        X += self.positional_embedding\n",
    "        return X\n",
    "\n",
    "\n",
    "class KMultiHeadAttention(keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__(dtype=FLOAT)\n",
    "        self.mha = keras.layers.MultiHeadAttention(\n",
    "            num_heads=heads,\n",
    "            key_dim=D_head,\n",
    "            output_shape=D_model,\n",
    "            use_bias=True,\n",
    "            dtype=FLOAT,\n",
    "        )\n",
    "\n",
    "    def call(self, X, attn_mask):\n",
    "        \"\"\"R^{BS x N x D_model}, R^{BS x N x N} -> R^{BS x N x D_model}\"\"\"\n",
    "        return self.mha(X, X, attention_mask=attn_mask)\n",
    "\n",
    "\n",
    "class TransformerBlock(keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__(dtype=FLOAT)\n",
    "        self.attn = KMultiHeadAttention()\n",
    "        self.norm1 = keras.layers.LayerNormalization(dtype=FLOAT)\n",
    "        self.norm2 = keras.layers.LayerNormalization(dtype=FLOAT)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [\n",
    "                keras.layers.Dense(\n",
    "                    D_fcn, activation=\"relu\", **commonDense\n",
    "                ),  # Switched to ReLU\n",
    "                keras.layers.Dense(D_model, **commonDense),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def call(self, X, A):\n",
    "        \"\"\"R^{BS x N x D_model} -> R^{BS x N x D_model}\"\"\"\n",
    "\n",
    "        A = tf.cast(A, dtype=tf.bool)\n",
    "        # NEW : pre norm blocks\n",
    "        X_norm = self.norm1(X)\n",
    "        X_attn = self.attn(X_norm, A)\n",
    "        X = X + X_attn\n",
    "        X_norm2 = self.norm2(X)\n",
    "        X_ffn = self.ffn(X_norm2)\n",
    "        X = X + X_ffn\n",
    "        return X\n",
    "\n",
    "\n",
    "# class Refiner(keras.layers.Layer):\n",
    "#     def __init__(self):\n",
    "#         super().__init__(dtype=FLOAT)\n",
    "#         self.conv1 = keras.layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\")\n",
    "#         self.conv2 = keras.layers.Conv2D(\n",
    "#             128, 3, dilation_rate=2, padding=\"same\", activation=\"relu\"\n",
    "#         )\n",
    "#         self.conv3 = keras.layers.Conv2D(3, 3, padding=\"same\")\n",
    "#\n",
    "#     def call(self, X):\n",
    "#         \"\"\"R^{BS x H x W x C} -> R^{BS x H x W x C}\"\"\"\n",
    "#         residual = X\n",
    "#         X = self.conv1(X)\n",
    "#         X = self.conv2(X)\n",
    "#         X = self.conv3(X)\n",
    "#         return X + residual\n",
    "\n",
    "\n",
    "class TransformerDecoder(keras.layers.Layer):\n",
    "    \"\"\"R^{BS x N x D_model} -> R^{BS x N x P*P*C}\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__(dtype=FLOAT)\n",
    "        self.proj1 = keras.layers.Dense(D_model, activation=\"gelu\", **commonDense)\n",
    "        self.proj2 = keras.layers.Dense(P * P * C, activation=\"sigmoid\", **commonDense)\n",
    "\n",
    "    def call(self, X):\n",
    "        BS = tf.shape(X)[0]\n",
    "        X = self.proj1(X)\n",
    "        X = self.proj2(X)\n",
    "        return tf.reshape(X, (BS, N, P, P, C))\n",
    "\n",
    "\n",
    "class ImageInpaintingTransformer(keras.Model):\n",
    "    \"\"\"outputs R ^ {BS x H x W x C}\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__(dtype=FLOAT)\n",
    "        self.embed = PatchEmbedding()\n",
    "        self.transformer_blocks = [TransformerBlock() for _ in range(num_layers)]\n",
    "        self.decoder = TransformerDecoder()\n",
    "        # self.refiner = Refiner()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        bs = input_shape[0]\n",
    "        dummy_masks = tf.zeros((bs, H, W, 1), dtype=FLOAT)  # THIS WASTED 40 MINUTES\n",
    "        dummy_imgs = tf.zeros((bs, H, W, C), dtype=FLOAT)  # THIS WASTED 40 MINUTES\n",
    "        self.call(dummy_imgs, dummy_masks)\n",
    "        # self.call(*next(iter(val_ds.take(1))))\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, image, obs_mask_float):\n",
    "        image = tf.multiply(image, obs_mask_float)\n",
    "        obs_mask_bool = tf.cast(obs_mask_float, dtype=tf.bool)\n",
    "        # viz_img(image[0])\n",
    "        patches = extract_patches(image)\n",
    "        AttnMask = create_attention_mask(obs_mask_bool)\n",
    "        # viz_img(AttnMask[0])\n",
    "\n",
    "        BS = tf.shape(patches)[0]\n",
    "        patches_flat = tf.reshape(patches, [BS, N, P ** 2 * C])\n",
    "        # tf.print(tf.shape(patches_flat))\n",
    "        X = self.embed(patches_flat)\n",
    "        for block in self.transformer_blocks:\n",
    "            X = block(X, AttnMask)\n",
    "\n",
    "        decoded = self.decoder(X)\n",
    "        return patches_to_imgs(decoded)\n",
    "\n",
    "\n",
    "model = ImageInpaintingTransformer()\n",
    "model.build((BATCH_SIZE, H, W, C))\n",
    "# model.compute_output_shape((BATCH_SIZE, H, W, C))\n",
    "model.summary()\n",
    "\n",
    "run_id = uuid.uuid4()\n",
    "print(run_id)\n",
    "session_epochs = 0\n",
    "session_steps = 0\n",
    "\n",
    "\n",
    "def cost_func(\n",
    "        y_true: tf.Tensor, y_pred: tf.Tensor, obs_mask_float: tf.Tensor\n",
    ") -> tf.RaggedTensor:\n",
    "    # errors = tf.square(tf.subtract(y_true, y_pred))\n",
    "    errors = tf.abs(tf.subtract(y_true, y_pred))\n",
    "    hole_mask = 1.0 - obs_mask_float  # type: ignore\n",
    "\n",
    "    hole_loss = tf.reduce_sum(errors * hole_mask) / (tf.reduce_sum(hole_mask) + 1e-8)\n",
    "    valid_loss = tf.reduce_sum(errors * obs_mask_float) / (tf.reduce_sum(obs_mask_float) + 1e-8)\n",
    "\n",
    "    return 2 * hole_loss + 1 * valid_loss\n",
    "\n",
    "\n",
    "def train_step(img: tf.Tensor, mask: tf.Tensor) -> tf.RaggedTensor:\n",
    "    with tf.GradientTape() as tape:\n",
    "        pred = model(img, mask, training=True)\n",
    "        loss = cost_func(img, pred, mask)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    if gradients is None:\n",
    "        raise RuntimeError()\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "\n",
    "def val_step(image: tf.Tensor, mask: tf.Tensor) -> tf.RaggedTensor:\n",
    "    reconstructed_img = model(image, mask, training=False)\n",
    "    loss = cost_func(image, reconstructed_img, mask)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def run_epoch(ds: tf.data.Dataset, step_fn, total_batches, desc):\n",
    "    total_loss = 0.0\n",
    "    steps = 0\n",
    "    pbar = tqdm(ds, desc=desc, unit=\"step\", total=total_batches)\n",
    "    for x, y in pbar:\n",
    "        loss = step_fn(x, y).numpy()\n",
    "        total_loss += loss\n",
    "        steps += 1\n",
    "        pbar.set_postfix(loss=f\"{float(loss):.4f}\")\n",
    "    return total_loss / steps\n",
    "\n",
    "\n",
    "import inspect\n",
    "import textwrap\n",
    "\n",
    "loss_source = textwrap.dedent(inspect.getsource(cost_func))\n",
    "run = None\n",
    "if WAN:\n",
    "    run = wandb.init(\n",
    "        entity=\"navidmafi-semnan-university\",\n",
    "        project=\"T1\",\n",
    "        dir=\"__wandb_logs\",\n",
    "        config={\n",
    "            \"optimizer\": optimizer.get_config(),\n",
    "            \"num_samples\": num_samples,\n",
    "            \"D_model\": D_model,\n",
    "            \"D_head\": D_head,\n",
    "            \"D_fcn\": D_fcn,\n",
    "            \"H\": H,\n",
    "            \"W\": W,\n",
    "            'P': P,\n",
    "            \"heads\": heads,\n",
    "            'Float': str(FLOAT),\n",
    "            \"num_layers\": num_layers,\n",
    "            \"batch_size\": BATCH_SIZE,\n",
    "            \"loss\": loss_source\n",
    "        },\n",
    "    )"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# model.load_weights(\"best_run.keras\")\n",
    "# model.save(name)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "assert isinstance(session_epochs, int)\n",
    "assert isinstance(session_steps, int)\n",
    "print(\n",
    "    f\"Starting training for {EPOCHS_TO_TRAIN - session_epochs} \"\n",
    "    f\"epochs (already did {session_epochs})\"\n",
    ")\n",
    "\n",
    "best_val_loss = float(\"inf\")\n",
    "best_epoch = -1\n",
    "for _ in range(EPOCHS_TO_TRAIN - session_epochs):\n",
    "    train_loss = run_epoch(train_ds, train_step, train_batches, f\"Epoch {session_epochs + 1}\")\n",
    "    val_loss = run_epoch(val_ds, val_step, val_batches, f\"Epoch {session_epochs + 1} Validation\")\n",
    "\n",
    "    if run:\n",
    "        run.log({'val/loss': val_loss, 'train/loss': train_loss, 'epoch': session_epochs})\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_epoch = session_epochs + 1\n",
    "        model.save(\"best_run.keras\")\n",
    "\n",
    "    session_epochs += 1"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# sample_img, sample_obs_mask_float = next(iter(train_ds.take(1)))\n",
    "sample_img, sample_obs_mask_float = next(iter(test_ds.take(1)))\n",
    "viz_grid(sample_img)\n",
    "viz_grid(apply_obs_mask(sample_img, sample_obs_mask_float))\n",
    "model_out = model(sample_img, sample_obs_mask_float)\n",
    "reconstructed = reconstruct(sample_img, model(sample_img, sample_obs_mask_float), sample_obs_mask_float)\n",
    "# viz_grid(reconstructed)\n",
    "viz_grid(model_out)\n",
    "print(\"PSNR\", tf.reduce_mean(tf.image.psnr(sample_img, model_out, max_val=1.0)).numpy())\n",
    "print(\"SSIM\", tf.reduce_mean(tf.image.ssim(sample_img, model_out, max_val=1.0)).numpy())"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf31211",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
